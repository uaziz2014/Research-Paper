{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-06T14:21:16.556223Z",
     "start_time": "2024-10-06T14:20:17.269543Z"
    }
   },
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "#device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "#print(device)\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"Hate-speech-CNERG/bert-base-uncased-hatexplain\", device=0)\n",
    "\n",
    "#, device=device\n",
    "# original_text = \"i dont think im getting my baby them white 9 he has two white j and nikes not even touched\"\n",
    "\n",
    "# classifier(original_text, return_all_scores=True)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Extract data from json file",
   "id": "71986b7ff554dddf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T18:42:07.144743Z",
     "start_time": "2024-10-06T18:42:06.127897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "json_file = './data/dataset.json'\n",
    "\n",
    "def extract_data(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    sentences = []\n",
    "    abuse_flags = []\n",
    "    annotated_labels = []\n",
    "    \n",
    "    for key, entry in data.items():\n",
    "        if 'post_tokens' in entry:\n",
    "            post_tokens = entry['post_tokens']\n",
    "            sentence = \" \".join(post_tokens)\n",
    "        else:\n",
    "            sentence = \" \"\n",
    "            print(f\"Warning: Entry {key} is missing 'post_tokens' key\")\n",
    "        \n",
    "        if 'annotators' in entry:\n",
    "            labels = [annotator['label'] for annotator in entry['annotators']]\n",
    "            if sum(label != \"normal\" for label in labels) >= 2:\n",
    "                abuse_label = 1  # Abusive\n",
    "            else:\n",
    "                abuse_label = 0  # normal\n",
    "            annotated_labels.append(labels)\n",
    "        else:\n",
    "            abuse_label = 0  # Default to normal if 'annotators' key is missing\n",
    "            annotated_labels.append([])\n",
    "            print(f\"Warning: Entry {key} is missing 'annotators' key\")\n",
    "        \n",
    "        sentences.append(sentence)\n",
    "        abuse_flags.append(abuse_label)\n",
    "\n",
    "    return sentences, abuse_flags, annotated_labels\n",
    "\n",
    "original_sentences, annotated_labels, annotated_labels_original = extract_data(json_file) #length = 20148\n",
    "\n",
    "file_path = \"./data/annotated_labels_original.json\"\n",
    "\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(annotated_labels_original, json_file)\n",
    "# print(len(original_sentences)) 20148\n",
    "# print(annotated_labels[:5])\n",
    "# print(classifier(original_sentences[:5], return_all_scores=True))"
   ],
   "id": "bdeea6d36bfa20f3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Do the predictions by the pipeline and extract classified results",
   "id": "e0c88b97b1417f38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:23:39.673875Z",
     "start_time": "2024-10-06T14:22:15.316486Z"
    }
   },
   "cell_type": "code",
   "source": "classified_result = classifier(original_sentences, batch_size=512)",
   "id": "dc6f1fa27c0da55d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T11:41:49.068067Z",
     "start_time": "2024-08-19T11:41:49.020269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from tqdm.auto import tqdm\n",
    "\n",
    "def extract_labels(result_labeled):\n",
    "    labels = []\n",
    "    \n",
    "    for instance in result_labeled:\n",
    "        if instance['label'] == 'normal':\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "#tqdm(classifier(original_sentences, batch_size=24), total=len(original_sentences))\n",
    "classified_labels = extract_labels(classified_result)\n",
    "\n",
    "# for out in results:\n",
    "#     print(out)\n",
    "\n",
    "print(classified_result[:10])\n",
    "print(classified_labels[:10])\n",
    "\n",
    "with open(\"./data/classified_labels.json\", \"w\") as f:\n",
    "    json.dump(classified_labels, f, indent=4)"
   ],
   "id": "55fa36da6e88a436",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'normal', 'score': 0.7708712220191956}, {'label': 'normal', 'score': 0.637093186378479}, {'label': 'hate speech', 'score': 0.6612201929092407}, {'label': 'hate speech', 'score': 0.6242997050285339}, {'label': 'offensive', 'score': 0.667515754699707}, {'label': 'hate speech', 'score': 0.920625627040863}, {'label': 'hate speech', 'score': 0.7545786499977112}, {'label': 'hate speech', 'score': 0.6379234194755554}, {'label': 'hate speech', 'score': 0.8680278658866882}, {'label': 'hate speech', 'score': 0.8520246744155884}]\n",
      "[0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Recalculate the classified labels, 3 tags",
   "id": "3c4253f9e3ef0440"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:24:46.212976Z",
     "start_time": "2024-10-06T14:24:46.175760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from tqdm.auto import tqdm\n",
    "\n",
    "def extract_labels(result_labeled):\n",
    "    labels = []\n",
    "    \n",
    "    for instance in result_labeled:\n",
    "        if instance['label'] == 'normal':\n",
    "            labels.append(1)\n",
    "        elif instance['label'] == 'hate speech':\n",
    "            labels.append(0)\n",
    "        elif instance['label'] == 'offensive':\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(-1) # cannot be recognized\n",
    "    \n",
    "    return labels\n",
    "\n",
    "#tqdm(classifier(original_sentences, batch_size=24), total=len(original_sentences))\n",
    "classified_labels_3_labels = extract_labels(classified_result)\n",
    "\n",
    "# for out in results:\n",
    "#     print(out)\n",
    "\n",
    "print(classified_result[:10])\n",
    "print(classified_labels_3_labels[:10])\n",
    "\n",
    "with open(\"./data/classified_labels_three_labels.json\", \"w\") as f:\n",
    "    json.dump(classified_labels_3_labels, f, indent=4)"
   ],
   "id": "adfa1d76293f8f46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'normal', 'score': 0.7708712220191956}, {'label': 'normal', 'score': 0.637093186378479}, {'label': 'hate speech', 'score': 0.6612201929092407}, {'label': 'hate speech', 'score': 0.6242997050285339}, {'label': 'offensive', 'score': 0.667515754699707}, {'label': 'hate speech', 'score': 0.920625627040863}, {'label': 'hate speech', 'score': 0.7545786499977112}, {'label': 'hate speech', 'score': 0.6379234194755554}, {'label': 'hate speech', 'score': 0.8680278658866882}, {'label': 'hate speech', 'score': 0.8520246744155884}]\n",
      "[1, 1, 0, 0, 2, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "  Calculate the scores",
   "id": "ff1b45253632aeea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T21:24:20.600362Z",
     "start_time": "2024-08-18T21:24:20.515521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(annotated_labels, classified_labels, average='binary')\n",
    "recall = recall_score(annotated_labels, classified_labels, average='binary')\n",
    "f1 = f1_score(annotated_labels, classified_labels, average='binary')\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
   ],
   "id": "b78fb2f80dbc3c07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8411602209944752, Recall: 0.8393870601589103, F1 Score: 0.84027270513757\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
