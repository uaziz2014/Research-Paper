{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c837beee0634fe",
   "metadata": {},
   "source": [
    "General Dataset and Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:05:54.597462Z",
     "start_time": "2024-08-12T13:05:53.225182Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"Hate-speech-CNERG/bert-base-uncased-hatexplain\", device=0)"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "6f6d04a7479a540b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:05:57.599490Z",
     "start_time": "2024-08-12T13:05:56.413814Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "json_file = './data/dataset.json'\n",
    "\n",
    "def extract_data(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    sentences = []\n",
    "    abuse_flags = []\n",
    "    \n",
    "    for key, entry in data.items():\n",
    "        if 'post_tokens' in entry:\n",
    "            post_tokens = entry['post_tokens']\n",
    "            sentence = \" \".join(post_tokens)\n",
    "        else:\n",
    "            sentence = \" \"\n",
    "            print(f\"Warning: Entry {key} is missing 'post_tokens' key\")\n",
    "        \n",
    "        if 'annotators' in entry:\n",
    "            labels = [annotator['label'] for annotator in entry['annotators']]\n",
    "            if sum(label != \"normal\" for label in labels) >= 2:\n",
    "                abuse_label = 0  # Abusive\n",
    "            else:\n",
    "                abuse_label = 1  # normal\n",
    "        else:\n",
    "            abuse_label = 0  # Default to normal if 'annotators' key is missing\n",
    "            print(f\"Warning: Entry {key} is missing 'annotators' key\")\n",
    "        \n",
    "        sentences.append(sentence)\n",
    "        abuse_flags.append(abuse_label)\n",
    "\n",
    "    return sentences, abuse_flags\n",
    "\n",
    "original_sentences, annotated_labels = extract_data(json_file) #length = 20148"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:05:58.376170Z",
     "start_time": "2024-08-12T13:05:58.370070Z"
    }
   },
   "cell_type": "code",
   "source": "# print(original_sentences[:5])",
   "id": "abdb04ac9f477ddf",
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "9a8da004c9c8f2eb",
   "metadata": {},
   "source": [
    "LIME"
   ]
  },
  {
   "cell_type": "code",
   "id": "df7c6f4e90cbc674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:06:00.527318Z",
     "start_time": "2024-08-12T13:06:00.520119Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "def predictor(texts):\n",
    "    # ä½¿ç”¨BERTæ¨¡å‹è¿›è¡Œé¢„æµ‹\n",
    "    predictions = classifier(texts, return_all_scores=True)\n",
    "    \n",
    "    # æå–æ¯ä¸ªé¢„æµ‹çš„åˆ†æ•°ï¼ˆæ¦‚ç‡ï¼‰ï¼Œå¹¶æŒ‰ç…§ä¸‰ä¸ªç±»åˆ«è¿”å›\n",
    "    # å‡è®¾classifierè¿”å›çš„æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«'labels'å’Œ'score'\n",
    "    # probs = []\n",
    "    # for result in predictions:\n",
    "    #     # åˆ›å»ºä¸€ä¸ªå«ä¸‰ä¸ªå…ƒç´ çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€ä¸ªç±»åˆ«çš„æ¦‚ç‡\n",
    "    #     prob = [0] * 3\n",
    "    #     if result['label'] == 'hate speech':\n",
    "    #         prob[0] = result['score']\n",
    "    #     elif result['label'] == 'normal':\n",
    "    #         prob[1] = result['score']\n",
    "    #     else:  # 'offensive'\n",
    "    #         prob[2] = result['score'] \n",
    "    #     probs.append(prob)\n",
    "        \n",
    "    # print(predictions)\n",
    "    result = []\n",
    "\n",
    "    # for item in predictions:\n",
    "    #     scores_list = [] * 3\n",
    "    #     for entry in item:\n",
    "    #         if entry['label'] == 'hate speech':\n",
    "    #             scores_list[0] = entry['score']\n",
    "    #         elif entry['label'] == 'normal':\n",
    "    #             scores_list[1] = entry['score']\n",
    "    #         elif entry['label'] == 'offensive':\n",
    "    #             scores_list[2] = entry['score']\n",
    "    #     result.append(scores_list)\n",
    "        # print(scores_list)\n",
    "    \n",
    "    for item in predictions:\n",
    "        scores_list = [entry['score'] for entry in item]\n",
    "        result.append(scores_list)\n",
    "    \n",
    "\n",
    "    result_array = np.array(result)\n",
    "    \n",
    "    return result_array"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:06:03.813071Z",
     "start_time": "2024-08-12T13:06:03.490215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(predictor(original_sentences[:5]))\n",
    "print(original_sentences[:5])"
   ],
   "id": "81806b617fe4f516",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z109649\\AppData\\Local\\miniconda3\\envs\\scientificProjectXAI\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03392262 0.7708711  0.19520631]\n",
      " [0.07430059 0.63709313 0.28860623]\n",
      " [0.66122037 0.16300514 0.17577441]\n",
      " [0.62429971 0.16513535 0.21056499]\n",
      " [0.07229818 0.26018623 0.66751558]]\n",
      "['i dont think im getting my baby them white 9 he has two white j and nikes not even touched', 'we cannot continue calling ourselves feminists if the rights of all womxn arent addressed yes to a sexual offences public list but will a trans lesbian bisexual and queer womxn be able to enter their information on the reporting sheet gender forum', 'nawt yall niggers ignoring me', '<user> i am bit confused coz chinese ppl can not access twitter thn how this ching chong using it i think he pakistani ğŸ¤” ğŸ¤” ğŸ¤”', 'this bitch in whataburger eating a burger with no top bun and holding it palm up i hate white bitches']\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "3321ee22b66f876d",
   "metadata": {},
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=['hate speech', 'normal', 'offensive'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "25e86e32069ff72",
   "metadata": {},
   "source": [
    "# é€‰æ‹©è¦è§£é‡Šçš„ä¸€ä¸ªå¥å­ï¼Œå‡è®¾æ˜¯ç¬¬ä¸€ä¸ªå¥å­\n",
    "# sentence_to_explain = original_sentences[]\n",
    "\n",
    "# ç”Ÿæˆè§£é‡Š\n",
    "for i, sentence in enumerate(original_sentences[:5]):\n",
    "    explanation = explainer.explain_instance(sentence, predictor, num_features=6, top_labels=3)\n",
    "    # æ˜¾ç¤ºè§£é‡Šç»“æœ\n",
    "    explanation.show_in_notebook(text=True)\n",
    "    explanation.save_to_file(f'explanation_{i}.html')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "60ad24443b5325a8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
