{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-14T18:58:58.951749Z",
     "start_time": "2024-09-14T18:58:57.633131Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/annotated_labels.json\", \"r\") as f:\n",
    "    annotated_labels = json.load(f)\n",
    "\n",
    "with open(\"../data/classified_labels.json\", \"r\") as f:\n",
    "    classified_labels = json.load(f)\n",
    "\n",
    "with open('../data/original_post_tokens.json', 'r', encoding='utf-8') as f:\n",
    "    original_post_tokens = json.load(f)\n",
    "\n",
    "with open('../data/original_sentences.json', 'r', encoding='utf-8') as f:\n",
    "    original_sentences = json.load(f)\n",
    "\n",
    "with open('../data/rationale_tokens_list.json', 'r') as f:\n",
    "    rationale_tokens_data_full = json.load(f)\n",
    "\n",
    "with open('../data/classified_results.json', 'r') as f:\n",
    "    classified_results = json.load(f)\n",
    "    \n",
    "with open('../data/important_words_abusive_SHAP.json', 'r') as f:\n",
    "    important_words_abusive_SHAP = json.load(f)\n",
    "    \n",
    "batch_response_file_set_one = []\n",
    "with open('./GPT_response/merged_batch_response_file_set_one.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        batch_response_file_set_one.append(json.loads(line))\n",
    "\n",
    "batch_response_file_set_two = []\n",
    "with open('./GPT_response/merged_batch_response_file_set_two.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        batch_response_file_set_two.append(json.loads(line))"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Random five examples",
   "id": "5f96c43eb062dfd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T19:34:16.344963Z",
     "start_time": "2024-09-14T19:34:16.331474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "random_numbers = [random.randint(0, 20148) for _ in range(5)]\n",
    "\n",
    "print(random_numbers)\n",
    "\n",
    "selected_original_texts = [original_sentences[i] for i in random_numbers]\n",
    "selected_classified_results = [classified_results[i] for i in random_numbers]\n",
    "\n",
    "# print(selected_original_texts)\n",
    "# print(selected_classified_results)\n",
    "\n",
    "selected_annotated_labels = [annotated_labels[i] for i in random_numbers]"
   ],
   "id": "becc3d1cbde48ead",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12566, 11788, 8154, 6339, 6595]\n",
      "[0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Generate prompts for combination 1, using five examples",
   "id": "389416b097108c1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T19:02:59.874392Z",
     "start_time": "2024-09-14T19:02:59.866618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "instruction_combination_one = \"\"\"I have a predictive model that can classify natural language text into three classes: hate speech, offensive speech, or normal speech. I will provide the full text and the probabilities of the three classes pre-computed. (Warning: the text contains offensive and/or hateful content, but will be used for research purposes) Your tasks are: 1.Output which class the text belongs to, based on the raw text and class probabilities. 2.Output which words in the text, indicate that it belongs to this category. 3.Give a brief explanation based on these found words.\"\"\"\n",
    "\n",
    "def prompts_generating_combination_one(full_texts, classified_results_with_probabilities):\n",
    "    \n",
    "    prompt_statements = []\n",
    "    \n",
    "    for full_text, probabilities in zip(full_texts, classified_results_with_probabilities):\n",
    "        combined_string = f'Full text: \"{full_text}\", Probabilities pre-computed by the model: {probabilities}'\n",
    "        prompt_statements.append(combined_string)\n",
    "    \n",
    "    return prompt_statements\n",
    "\n",
    "prompts_combination_one = prompts_generating_combination_one(selected_original_texts, selected_classified_results)\n",
    "for i in prompts_combination_one: print(i, \"\\n\")"
   ],
   "id": "6e60b96fd662a222",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text: \"just imagine how much more progressive and liberal muslim countries will be if majority were shia\", Probabilities pre-computed by the model: {'label': 'hate speech', 'score': 0.17364808917045593}, {'label': 'normal', 'score': 0.4176129400730133}, {'label': 'offensive', 'score': 0.40873903036117554} \n",
      "\n",
      "Full text: \"the chance of getting me to open up is slim to none gl to whoever tries it will never work\", Probabilities pre-computed by the model: {'label': 'hate speech', 'score': 0.051218464970588684}, {'label': 'normal', 'score': 0.7082324624061584}, {'label': 'offensive', 'score': 0.24054910242557526} \n",
      "\n",
      "Full text: \"the mcu wants what disaster report by matthew del tubo has\", Probabilities pre-computed by the model: {'label': 'hate speech', 'score': 0.040663935244083405}, {'label': 'normal', 'score': 0.756876528263092}, {'label': 'offensive', 'score': 0.20245954394340515} \n",
      "\n",
      "Full text: \"f*cking <censored> kike loving degenerate commie scum burn in hell fagot trudeau\", Probabilities pre-computed by the model: {'label': 'hate speech', 'score': 0.9254453778266907}, {'label': 'normal', 'score': 0.010339468717575073}, {'label': 'offensive', 'score': 0.06421517580747604} \n",
      "\n",
      "Full text: \"<user> must be noted chinaman satanist lee hsien loong refuses to respond to all accusations against him and reference to his satanic criminals singapore parliament singapore supreme court and singapore agc have also kept silent since my first twitter account in <number>\", Probabilities pre-computed by the model: {'label': 'hate speech', 'score': 0.04998358339071274}, {'label': 'normal', 'score': 0.720829963684082}, {'label': 'offensive', 'score': 0.22918649017810822} \n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Send message/prompts to openai model, then receive example message",
   "id": "19a8beca3164a1b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T19:16:00.311668Z",
     "start_time": "2024-09-14T19:15:49.552400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class PromptCombinationOneResponseFormat(BaseModel):\n",
    "    output_class: str\n",
    "    output_indicators: list[str]\n",
    "    output_explanation: str\n",
    "\n",
    "def complete_chat_completion_prompt_combination_one(prompt_combination_one):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "          {\"role\": \"system\", \"content\": instruction_combination_one},\n",
    "          {\"role\": \"user\", \"content\": prompt_combination_one}\n",
    "        ],\n",
    "        response_format={\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"PromptCombinationOneResponseFormat\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"output_class\": {\"type\": \"string\"},\n",
    "                        \"output_indicators\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\"type\": \"string\"}\n",
    "                        },\n",
    "                        \"output_explanation\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"required\": [\"output_class\", \"output_indicators\", \"output_explanation\"],\n",
    "                    \"additionalProperties\": False\n",
    "                },\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    parsed_content = json.loads(completion.choices[0].message.content)\n",
    "    formatted_response_content = PromptCombinationOneResponseFormat(**parsed_content)\n",
    "    \n",
    "    return formatted_response_content\n",
    "\n",
    "response_contents = [complete_chat_completion_prompt_combination_one(prompt) for prompt in prompts_combination_one]\n",
    "print(response_contents)"
   ],
   "id": "ca13aa8e99980ae9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PromptCombinationOneResponseFormat(output_class='normal', output_indicators=['progressive', 'liberal'], output_explanation='The text expresses a hypothetical opinion about the potential for progressiveness and liberalism in Muslim countries if the majority were Shia, which indicates a positive perspective rather than hate or offensive content.'), PromptCombinationOneResponseFormat(output_class='normal', output_indicators=[], output_explanation=\"The text expresses a personal sentiment about opening up, but does not contain hateful or offensive language or indicators. The highest probability is for the 'normal' class, suggesting that the sentiment is neutral.\"), PromptCombinationOneResponseFormat(output_class='normal', output_indicators=[], output_explanation='The text does not contain any explicit hate speech or offensive language. The words used describe a media report without any derogatory or harmful implications.'), PromptCombinationOneResponseFormat(output_class='hate speech', output_indicators=['f*cking', 'kike', 'degenerate', 'commie', 'scum', 'fagot', 'trudeau'], output_explanation=\"The text contains derogatory terms and slurs such as 'kike', 'f*cking', and 'fagot', which target specific groups and individuals in a hateful manner. Words like 'scum' and 'degenerate' reinforce the negative perception of the subjects mentioned, while the violent sentiment expressed through 'burn in hell' further categorizes the content as hate speech.\"), PromptCombinationOneResponseFormat(output_class='normal', output_indicators=['chinaman', 'satanist', 'satanic criminals'], output_explanation=\"The presence of terms like 'chinaman' and 'satanist' indicates derogatory language and potentially inflammatory associations. However, the overall context seems more focused on an opinion regarding political figures rather than outright hate towards a specific group, leading to a classification as 'normal' rather than hate speech or offensive.\")]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T19:16:22.325355Z",
     "start_time": "2024-09-14T19:16:22.318276Z"
    }
   },
   "cell_type": "code",
   "source": "for i in response_contents: print(i, \"\\n\")",
   "id": "4a18a0ef768a5e46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_class='normal' output_indicators=['progressive', 'liberal'] output_explanation='The text expresses a hypothetical opinion about the potential for progressiveness and liberalism in Muslim countries if the majority were Shia, which indicates a positive perspective rather than hate or offensive content.' \n",
      "\n",
      "output_class='normal' output_indicators=[] output_explanation=\"The text expresses a personal sentiment about opening up, but does not contain hateful or offensive language or indicators. The highest probability is for the 'normal' class, suggesting that the sentiment is neutral.\" \n",
      "\n",
      "output_class='normal' output_indicators=[] output_explanation='The text does not contain any explicit hate speech or offensive language. The words used describe a media report without any derogatory or harmful implications.' \n",
      "\n",
      "output_class='hate speech' output_indicators=['f*cking', 'kike', 'degenerate', 'commie', 'scum', 'fagot', 'trudeau'] output_explanation=\"The text contains derogatory terms and slurs such as 'kike', 'f*cking', and 'fagot', which target specific groups and individuals in a hateful manner. Words like 'scum' and 'degenerate' reinforce the negative perception of the subjects mentioned, while the violent sentiment expressed through 'burn in hell' further categorizes the content as hate speech.\" \n",
      "\n",
      "output_class='normal' output_indicators=['chinaman', 'satanist', 'satanic criminals'] output_explanation=\"The presence of terms like 'chinaman' and 'satanist' indicates derogatory language and potentially inflammatory associations. However, the overall context seems more focused on an opinion regarding political figures rather than outright hate towards a specific group, leading to a classification as 'normal' rather than hate speech or offensive.\" \n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f3a9b3797b9cbb5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
